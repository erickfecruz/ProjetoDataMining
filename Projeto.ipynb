{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto para Disciplina de Mineração de Dados  \n",
    "## Aplicação de Técnica de classificação para Solução de Captcha  Sonoro\n",
    "### Programa de Pós Graduação em Computação UFABC - 2º Quadrimestre de 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrantes:\n",
    "Erick Fernandes da Cruz <br>\n",
    "Gustavo Borges Lugoboni <br>\n",
    "Igor Esteves de Oliveira "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código Desenvolvido\n",
    "\n",
    "A seguir se encontram as bibliotecas que foram utilizadas para o desenvolvimento do presente projeto necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bibliotecas utilizadas\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import IPython.display as ipd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira etapa que desenvolvemos foi a separação das letras que eram obtidas em cada audio que continha 4 caracteres, para isso utilizamos 2 arrays inicialmente, um deles contendo a onda especifica de cada letra do conjunto de treinamento e o outro com a letra correspondente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArrayLetras = list()\n",
    "Y = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para separar as letras desenvolvemos a função separar_letras que tem como objetivo receber um audio com 4 letras, dividir em 4 audios menores e a partir desses audios menores eliminar a maior parte do ruído possível através de uma frequência de corte para ter uma melhor representação de cada letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_letras(data, fs, destination_array) :\n",
    "\n",
    "    #Separar em 4 conjuntos \n",
    "    n = 4\n",
    "    splited = []\n",
    "    len_l = len(data)\n",
    "    for i in range(n):\n",
    "        start = int(i*len_l/n)\n",
    "        end = int((i+1)*len_l/n)\n",
    "        splited.append(data[start:end])\n",
    "    \n",
    "    frame_lenght = 6300 # frames de fs/14 aprox 0.5s\n",
    "    \n",
    "    chars_values = list()\n",
    "    \n",
    "    for audioPart in range(4):\n",
    "        initial_frame_pos = 0 \n",
    "        frames_list = list()\n",
    "\n",
    "        #Separando os frames\n",
    "        while initial_frame_pos < len(splited[audioPart]):\n",
    "            frames_list.append(splited[audioPart][initial_frame_pos : initial_frame_pos+frame_lenght])\n",
    "            initial_frame_pos += frame_lenght\n",
    "\n",
    "        #Filtrando por amplitude maxima do frame inicial (supondo que é sempre ruido ou silencio) + desvio padrao\n",
    "        amp_cat_values = list()\n",
    "\n",
    "        max_values = [max(x) for x in frames_list] \n",
    "        max_values.sort()\n",
    "        max_value_mean = np.mean(max_values)\n",
    "        max_value_std = np.std(max_values)\n",
    "\n",
    "        for frame in frames_list:\n",
    "            frame_max = max(abs(frame))\n",
    "            #se o frame tiver amplitude maxima <= a inicial std consideramos como um trecho de audio valido      \n",
    "            if frame_max <= max_value_mean + max_value_std**2 :  \n",
    "                if frame_max >= max_value_mean - max_value_std**2 :\n",
    "                    amp_cat_values.append(\"max\")\n",
    "                else:\n",
    "                    amp_cat_values.append(\"min\")\n",
    "            else:\n",
    "                amp_cat_values.append(\"max\")\n",
    "\n",
    "        # guardando os idices dos frames de frames_list onde a amplitude equivale a um valor de audio valido\n",
    "        max_indexes = list()\n",
    "        index_list = range(0, len(amp_cat_values))\n",
    "        amp_cat_values = list(zip(index_list, amp_cat_values))\n",
    "\n",
    "        max_indexes = [index for index in amp_cat_values if index[1] is \"max\"]\n",
    "\n",
    "        #agrupando por indices a uma distancia <= 2 posições (separando os caracteres)\n",
    "        chars_indexes = list()\n",
    "        new_frame = list()\n",
    "        new_frame.append(max_indexes[0])\n",
    "        for frame_info in max_indexes:\n",
    "            if frame_info[0] - new_frame[-1][0] <= 2:\n",
    "                if frame_info not in new_frame:\n",
    "                    new_frame.append(frame_info)\n",
    "            else:\n",
    "                chars_indexes.append(new_frame)\n",
    "                new_frame = list()\n",
    "                new_frame.append(frame_info)\n",
    "            if frame_info is max_indexes[-1]:\n",
    "                chars_indexes.append(new_frame)\n",
    "\n",
    "        # filtrando os indices no vetor de frames_list (contendo as amostras originais) para separar as amostras de\n",
    "        # caracteres validos\n",
    "        initialBigger = 0\n",
    "        lastBigger = 0\n",
    "\n",
    "        diferenca = 0\n",
    "\n",
    "        for index in chars_indexes:\n",
    "            initial = index[0][0] \n",
    "            last = index[-1][0] \n",
    "\n",
    "            if (last - initial) > diferenca:\n",
    "                initialBigger = initial\n",
    "                lastBigger = last\n",
    "\n",
    "        if (initialBigger != 0):\n",
    "            initialBigger = initialBigger - 1\n",
    "        \n",
    "        value = np.hstack(frames_list[initialBigger:lastBigger+1])\n",
    "        destination_array.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que tinhamos a função pronta criamos um laço que percorre todos os arquivos na pasta do conjunto de treinamento para que pudessemos recolher os dados para que estes fossem manipulados em um momento futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(\"treino/\"):  \n",
    "    \n",
    "    for filename in files:\n",
    "        \n",
    "        data, fs = librosa.load('treino/' + filename, None)\n",
    "        for s in range(4):\n",
    "            Y.append(filename[s])\n",
    "            \n",
    "        separar_letras(data, fs, ArrayLetras)\n",
    "\n",
    "print(len(ArrayLetras))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PARTIR DAQUI É TUDO TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraindo informações\n",
    "duration = np.array([len(x)/fs for x in ArrayLetras])\n",
    "\n",
    "tempo_beat = [librosa.beat.beat_track(y=x, sr=fs) for x in ArrayLetras]\n",
    "tempo = np.array([x[0] for x in tempo_beat])\n",
    "beat_frame = np.array([x[1] for x in tempo_beat])\n",
    "\n",
    "mean_percussive = np.array([librosa.effects.hpss(x)[1].mean() for x in ArrayLetras])\n",
    "\n",
    "sftf = [librosa.stft(x) for x in ArrayLetras]\n",
    "mean_freq = np.array([np.abs(x).mean() for x in sftf])\n",
    "\n",
    "mean_centroid = [librosa.feature.spectral_centroid(y=x, sr=fs).mean() for x in ArrayLetras]\n",
    "\n",
    "train_base = np.array(list(zip(duration, tempo, mean_percussive, mean_freq, mean_centroid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando base de testes\n",
    "Array_test = list()\n",
    "Y_test = list()\n",
    "for root, dirs, files in os.walk(\"teste/\"):  \n",
    "    \n",
    "    for filename in files:\n",
    "        \n",
    "        data, fs = librosa.load('teste/' + filename, None)\n",
    "        for s in range(4):\n",
    "            Y_test.append(filename[s])\n",
    "            \n",
    "        separar_letras(data, fs, Array_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraindo informações\n",
    "duration_test = np.array([len(x)/fs for x in Array_test])\n",
    "\n",
    "tempo_beat_test = [librosa.beat.beat_track(y=x, sr=fs) for x in Array_test]\n",
    "tempo_test = np.array([x[0] for x in tempo_beat_test])\n",
    "beat_frame_test = np.array([x[1] for x in tempo_beat_test])\n",
    "\n",
    "mean_percussive_test = np.array([librosa.effects.hpss(x)[1].mean() for x in Array_test])\n",
    "\n",
    "sftf_test = [librosa.stft(x) for x in Array_test]\n",
    "mean_freq_test = np.array([np.abs(x).mean() for x in sftf_test])\n",
    "\n",
    "mean_centroid_test = [librosa.feature.spectral_centroid(y=x, sr=fs).mean() for x in Array_test]\n",
    "\n",
    "test_base = np.array(list(zip(duration_test, tempo_test, mean_percussive_test, mean_freq_test, mean_centroid_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.2348633e-03 -2.6855469e-03  3.0517578e-05 ... -1.3732910e-03\n",
      " -6.1035156e-05 -7.9345703e-04]\n"
     ]
    }
   ],
   "source": [
    "print(Array_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(train_base, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "582\n"
     ]
    }
   ],
   "source": [
    "false = 0\n",
    "true = 0\n",
    "for x in range(0, len(test_base)):\n",
    "    if gnb.predict([test_base[x]])[0] == Y_test[x]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(true)\n",
    "print(false)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminante Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(train_base, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n",
      "571\n"
     ]
    }
   ],
   "source": [
    "false = 0\n",
    "true = 0\n",
    "for x in range(0, len(test_base)):\n",
    "    if clf.predict([test_base[x]])[0] == Y_test[x]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(true)\n",
    "print(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train = preprocessing.normalize(train_base, norm='l1')\n",
    "norm_test = preprocessing.normalize(test_base, norm='l1')\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(norm_train, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n",
      "651\n"
     ]
    }
   ],
   "source": [
    "false = 0\n",
    "true = 0\n",
    "for x in range(0, len(test_base)):\n",
    "    if neigh.predict([norm_test[x]])[0] == Y_test[x]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(true)\n",
    "print(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = tree.DecisionTreeClassifier()\n",
    "dtr = dtr.fit(train_base, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "535\n"
     ]
    }
   ],
   "source": [
    "false = 0\n",
    "true = 0\n",
    "for x in range(0, len(test_base)):\n",
    "    if dtr.predict([test_base[x]])[0] == Y_test[x]:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "print(true)\n",
    "print(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
